{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Données, pré-traitement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tools import *\n",
    "from embeddings import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb comments: 159571 (y_shape: (159571, 6))\n"
     ]
    }
   ],
   "source": [
    "# load raw string data\n",
    "data_train, y_train_all, data_test, id_test = load_data()\n",
    "\n",
    "print('Nb comments: {} (y_shape: {})'.format(len(data_train), y_train_all.shape))\n",
    "#print(y_train_all.sum(0)/y_train_all.shape[0])\n",
    "\n",
    "\n",
    "DATA_AUGMENT = False\n",
    "# If data augmentation, load \"translated data\" and add to dataset only negatives examples\n",
    "y_train_all_no_aug = y_train_all \n",
    "if DATA_AUGMENT:\n",
    "    y_train_all_toxic_idx = np.where(np.sum(y_train_all, axis=1)!=0)[0]\n",
    "\n",
    "    for language_extension in ['_fr', '_es', '_de']:\n",
    "        print(language_extension)\n",
    "        data_train_lg, _, _ ,_ = load_data(language=language_extension)\n",
    "        data_train_lg_toxic = [data_train_lg[idx] for idx in y_train_all_toxic_idx] \n",
    "        data_train += data_train_lg_toxic\n",
    "        y_train_all = np.vstack((y_train_all, y_train_all[y_train_all_toxic_idx]))\n",
    "\n",
    "    print('Nb comments after data augment: {} (y_shape: {})'.format(len(data_train), y_train_all.shape))\n",
    "    #print(y_train_all.sum(0)/y_train_all.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_AUGMENT==True:\n",
    "    plt.figure()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    y_train_all_no_aug_binary = np.atleast_2d(np.sum(y_train_all_no_aug, axis=1)).T\n",
    "    y_train_all_no_aug_binary[y_train_all_no_aug_binary>0] = 1\n",
    "    \n",
    "    y_train_all_binary = np.atleast_2d(np.sum(y_train_all, axis=1)).T\n",
    "    y_train_all_binary[y_train_all_binary>0] = 1\n",
    "\n",
    "    \n",
    "    plt.title('Class imbalance with data augmentation:\\n {} vs. {} examples'.format(np.shape(y_train_all_no_aug)[0], np.shape(y_train_all)[0]))\n",
    "    plt.bar(['clean']+CLASSES, [y_train_all_binary.shape[0]- np.sum(y_train_all_binary)] + list(np.sum(y_train_all, axis=0)), color='r')\n",
    "    plt.bar(['clean']+CLASSES, [y_train_all_no_aug_binary.shape[0]- np.sum(y_train_all_no_aug_binary)] + list(np.sum(y_train_all_no_aug, axis=0)))\n",
    "    plt.xticks(rotation=80)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données (optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\n",
      "-------\n",
      "Hey man I m really not try to edit war It s just that this guy be constantly remove relevant information and talk to me through edit instead of my talk page He seem to care more about the format than the actual info\n"
     ]
    }
   ],
   "source": [
    "params = {'lower': False, \n",
    "          'lemma': True, \n",
    "          'stop_words': False}\n",
    "\n",
    "comment = data_train[2]\n",
    "print(comment)\n",
    "print('-------')\n",
    "print(CommentCleaner(**params).transform(comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: 100%       \n",
      "Transformation: 100%       \n"
     ]
    }
   ],
   "source": [
    "clean_data_train = transform_dataset(data_train, transformer=CommentCleaner, kwargs=params)\n",
    "clean_data_test = transform_dataset(data_test, transformer=CommentCleaner, kwargs=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion numérique des données textuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODING: Fitting vectorizer to data\n",
      "ENCODING: transforming data to numerical\n"
     ]
    }
   ],
   "source": [
    "# Convert strings to int indexes, \n",
    "# considering only the VOCAB_SIZE most common words, \n",
    "# and pad the sentences to SENTENCE_LENGTH words\n",
    "VOCAB_SIZE = 30000\n",
    "## TODO: set parameters in a better way\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 1),\n",
    "                                   min_df=10, max_features=VOCAB_SIZE, use_idf=True, smooth_idf=True,\n",
    "                                   sublinear_tf=True)\n",
    "\n",
    "# count_vectorizer = CountVectorizer(analyzer='word', stop_words='english',\n",
    "#                                  strip_accents='unicode', max_features=VOCAB_SIZE)\n",
    "\n",
    "\n",
    "# X_train_all, X_test = encode(data_train, data_test, vectorizer=tokens_vectorizer)\n",
    "X_train_all, X_test = encode(clean_data_train, clean_data_test, vectorizer=tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction des features auxiliaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing comments length\n",
      "Transformation: 100%       \n",
      "Transformation: 100%       \n",
      "Computing number of punctuation marks in comments\n",
      "Transformation: 100%       \n",
      "Transformation: 100%       \n",
      "Computing number of upper cased words in comments\n",
      "Transformation: 100%       \n",
      "Transformation: 100%       \n"
     ]
    }
   ],
   "source": [
    "print(\"Computing comments length\")\n",
    "comments_lengths_train = np.array(transform_dataset(data_train, transformer=CommentLength, n_prints=5))\n",
    "comments_lengths_test = np.array(transform_dataset(data_test, transformer=CommentLength, n_prints=5))\n",
    "\n",
    "print(\"Computing number of punctuation marks in comments\")\n",
    "params = {'divide_by_len': True, 'chars_set': {'!'}}\n",
    "comments_punctuation_train = np.array(transform_dataset(data_train, transformer=CharCounter, kwargs=params))\n",
    "comments_punctuation_test = np.array(transform_dataset(data_test, transformer=CharCounter, kwargs=params))\n",
    "\n",
    "print(\"Computing number of upper cased words in comments\")\n",
    "params = {'divide_by_len': True}\n",
    "comments_upperwords_train = np.array(transform_dataset(data_train, transformer=UppercaseWordsCounter, kwargs=params))\n",
    "comments_upperwords_test = np.array(transform_dataset(data_test, transformer=UppercaseWordsCounter, kwargs=params))\n",
    "\n",
    "# concatenation of auxiliary features\n",
    "X_aux_train_all = np.vstack((comments_lengths_train, comments_punctuation_train, comments_upperwords_train)).T\n",
    "X_aux_test = np.vstack((comments_lengths_test, comments_punctuation_test, comments_upperwords_test)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_VALID_RATIO = 0.10\n",
    "SPLIT_RANDOM_SEED = 0  # TODO : check split because of imbalanced classes\n",
    "\n",
    "# numerical comments\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_all, y_train_all, \n",
    "                                                      test_size=SPLIT_VALID_RATIO,\n",
    "                                                      random_state=SPLIT_RANDOM_SEED)\n",
    "\n",
    "# auxiliary input\n",
    "X_aux_train, X_aux_valid, _, _ = train_test_split(X_aux_train_all, y_train_all, \n",
    "                                                  test_size=SPLIT_VALID_RATIO,\n",
    "                                                  random_state=SPLIT_RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBSVM on TFIDF/CBOW/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C':6*[0.5],\n",
    "          'dual': 6*[False],\n",
    "          'solver': 6*['lbfgs']}\n",
    "USE_AUX_FEATURES = False\n",
    "MODEL_NAME = 'only_lemma_no_aux_TFIDF_NBSVM_C_4'\n",
    "\n",
    "model = OneVAllClassifier(n_classes=6, clf=NbSvmClassifier, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 0:\n",
      "Fitting model 1:\n",
      "Fitting model 2:\n",
      "Fitting model 3:\n",
      "Fitting model 4:\n",
      "Fitting model 5:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVAllClassifier(clf=None, n_classes=6, params=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(hstack((X_train, X_aux_train)).astype(int).tocsr() if USE_AUX_FEATURES else X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict_proba(hstack((X_train, X_aux_train)).astype(int).tocsr() if USE_AUX_FEATURES else X_train)\n",
    "y_valid_pred = model.predict_proba(hstack((X_valid, X_aux_valid)).astype(int).tocsr() if USE_AUX_FEATURES else X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score on train set : 0.9958\n",
      "ROC-AUC score on validation set : 0.9808\n"
     ]
    }
   ],
   "source": [
    "train_score = evaluate(y_train, y_train_pred)\n",
    "print(\"ROC-AUC score on train set : {:.4f}\".format(train_score))\n",
    "\n",
    "valid_score = evaluate(y_valid, y_valid_pred)\n",
    "print(\"ROC-AUC score on validation set : {:.4f}\".format(valid_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all_pred = model.predict_proba(hstack((X_train_all, X_aux_train_all)).astype(int).tocsr() if USE_AUX_FEATURES else X_train_all)\n",
    "save_pred(y_train_all_pred, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_test_pred = model.predict_proba(hstack((X_test, X_aux_test)).astype(int).tocsr() if USE_AUX_FEATURES else X_test)\n",
    "# write submission file\n",
    "submission(y_test_pred, id_test, name=MODEL_NAME)\n",
    "save_pred(y_test_pred, MODEL_NAME+'_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage sur features auxiliaires seules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVAllClassifier(clf=None, n_classes=6, params=None)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'C':6*[0.5],\n",
    "          'dual': 6*[False],\n",
    "          'solver': 6*['lbfgs']}\n",
    "\n",
    "model = OneVAllClassifier(n_classes=6, clf=NbSvmClassifier, params=params)\n",
    "model.fit(sparse.csr_matrix(X_aux_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict_proba(sparse.csr_matrix(X_aux_train))\n",
    "y_valid_pred = model.predict_proba(sparse.csr_matrix(X_aux_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score on train set : 0.6269\n",
      "ROC-AUC score on validation set : 0.6353\n"
     ]
    }
   ],
   "source": [
    "train_score = evaluate(y_train, y_train_pred)\n",
    "print(\"ROC-AUC score on train set : {:.4f}\".format(train_score))\n",
    "\n",
    "valid_score = evaluate(y_valid, y_valid_pred)\n",
    "print(\"ROC-AUC score on validation set : {:.4f}\".format(valid_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autres modèles que NBSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthou/.local/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# GradientBoostingC/R doesnt have predict_proba, GaussianNB need dense data (impossible here, due to RAM limitation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_AUX_FEATURES = False\n",
    "\n",
    "params_RFC = {}\n",
    "params_XGB = {'n_jobs':6*[4]}\n",
    "MODEL_NAME = 'XGB'\n",
    "model = OneVAllClassifier(n_classes=6, clf=XGBClassifier, params=params_XGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 0:\n",
      "Fitting model 1:\n",
      "Fitting model 2:\n",
      "Fitting model 3:\n",
      "Fitting model 4:\n",
      "Fitting model 5:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVAllClassifier(clf=None, n_classes=6, params=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(hstack((X_train, X_aux_train)).astype(int).tocsr() if USE_AUX_FEATURES else X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict_proba(hstack((X_train, X_aux_train)).astype(int).tocsr() if USE_AUX_FEATURES else X_train)\n",
    "y_valid_pred = model.predict_proba(hstack((X_valid, X_aux_valid)).astype(int).tocsr() if USE_AUX_FEATURES else X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all_pred = model.predict_proba(hstack((X_train_all, X_aux_train_all)).astype(int).tocsr() if USE_AUX_FEATURES else X_train_all)\n",
    "save_pred(y_train_all_pred, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score on train set : 0.9523\n",
      "ROC-AUC score on validation set : 0.9465\n"
     ]
    }
   ],
   "source": [
    "train_score = evaluate(y_train, y_train_pred)\n",
    "print(\"ROC-AUC score on train set : {:.4f}\".format(train_score))\n",
    "\n",
    "valid_score = evaluate(y_valid, y_valid_pred)\n",
    "print(\"ROC-AUC score on validation set : {:.4f}\".format(valid_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_test_pred = model.predict_proba(hstack((X_test, X_aux_test)).astype(int).tocsr() if USE_AUX_FEATURES else X_test)\n",
    "# write submission file\n",
    "#submission(y_test_pred, id_test, name=MODEL_NAME) \n",
    "save_pred(y_test_pred, MODEL_NAME+'_test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
